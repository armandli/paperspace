{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038d24d0-d384-4e3c-b42f-2d17800912d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import torch\n",
    "from torch import utils\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToPILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0d095c-29d5-4ecc-a9ef-a0f04eaac242",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='./data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11dab1f3-221e-401f-be38-e0dfe9ed7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_built()\n",
    "if use_cuda:\n",
    "    device = torch.device('cuda')\n",
    "elif use_mps:\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0162115b-131c-495d-8db8-6aee90fb3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_batch_size = 256\n",
    "loader_args = {'batch_size' : default_batch_size, 'shuffle' : True}\n",
    "score_args = {'batch_size' : default_batch_size, 'shuffle' : False}\n",
    "if use_cuda:\n",
    "    loader_args.update({'pin_memory' : True})\n",
    "    score_args.update({'pin_memory' : True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7293d673-0255-4a1d-a985-40499c777b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reporter(ABC):\n",
    "    @abstractmethod\n",
    "    def report(self, typ, **metric):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbffa8c1-aaa3-4d38-8d3c-efffe3532c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SReporter(Reporter):\n",
    "    def __init__(self):\n",
    "        self.log = []\n",
    "    def report(self, typ, **data):\n",
    "        self.log.append((typ, data))\n",
    "    def reset(self):\n",
    "        self.log.clear()\n",
    "    def loss(self, t):\n",
    "        losses = []\n",
    "        for (typ, data) in self.log:\n",
    "            if typ == t:\n",
    "                losses.append(data['loss'])\n",
    "        return losses\n",
    "    def loss(self, t, idx):\n",
    "        if idx >= 0:\n",
    "            count = 0\n",
    "            for (typ, data) in self.log:\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data['loss']\n",
    "                    count += 1\n",
    "        else:\n",
    "            count = -1\n",
    "            for (typ, data) in reversed(self.log):\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data['loss']\n",
    "                    count -= 1\n",
    "        return float(\"inf\")\n",
    "    def eval_loss(self):\n",
    "        return self.loss('eval')\n",
    "    def train_loss(self):\n",
    "        return self.loss('train')\n",
    "    def eval_loss(self, idx):\n",
    "        return self.loss('eval', idx)\n",
    "    def train_loss(self, idx):\n",
    "        return self.loss('train', idx)\n",
    "    def get_record(self, t, idx):\n",
    "        if idx >= 0:\n",
    "            count = 0\n",
    "            for (typ, data) in self.log:\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data\n",
    "                    count += 1\n",
    "        else:\n",
    "            count = -1\n",
    "            for (typ, data) in reversed(self.log):\n",
    "                if typ == t:\n",
    "                    if count == idx:\n",
    "                        return data\n",
    "                    count -= 1\n",
    "        return dict()\n",
    "    def eval_record(self, idx):\n",
    "        return self.get_record('eval', idx)\n",
    "    def train_record(self, idx):\n",
    "        return self.get_record('train', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41230be-01b3-4e9b-a431-720bcd236861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAELoss, self).__init__()\n",
    "    \n",
    "    def forward(self, pred, target, mu, sig):\n",
    "        recon_loss = ((target - pred)**2.).sum()\n",
    "        dkl_loss = (sig**2. + mu**2. - torch.log(sig) - 0.5).sum()\n",
    "        return recon_loss + dkl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b04a59b5-3dea-45fc-aa13-01ea76ed8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_activation():\n",
    "    return nn.ReLU(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dadec496-8669-44a9-adcc-44e9dd7b4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling2DV2(in_c, out_c, stride, norm_layer):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, 1, stride=stride),\n",
    "        norm_layer(out_c),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2a54af5-8d99-4625-a0cc-2960b48d6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling2DV1(in_c, out_c, stride, norm_layer):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_c, out_c, 2, stride=stride),\n",
    "        norm_layer(out_c),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb8f0918-9769-4f5e-8e83-12deb088ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualLayer2DV4(nn.Module):\n",
    "    def __init__(self, in_c, out_c, ksz, act_layer, norm_layer, stride=1):\n",
    "        super(ResidualLayer2DV4, self).__init__()\n",
    "        if in_c <= out_c:\n",
    "            self.c1 = nn.Conv2d(in_c, out_c, ksz, stride=stride, padding=int((ksz-1)/2))\n",
    "            self.c2 = nn.Conv2d(out_c, out_c, ksz, stride=1, padding=int((ksz-1)/2))\n",
    "        else:\n",
    "            self.c1 = nn.ConvTranspose2d(in_c, out_c, ksz+1, stride=stride, padding=int((ksz-1)/2))\n",
    "            self.c2 = nn.ConvTranspose2d(out_c, out_c, ksz, stride=1, padding=int((ksz-1)/2))\n",
    "        self.a1 = act_layer()\n",
    "        self.a2 = act_layer()\n",
    "        self.b1 = norm_layer(in_c)\n",
    "        self.b2 = norm_layer(out_c)\n",
    "        \n",
    "        if in_c < out_c:\n",
    "            self.residual = downsampling2DV2(in_c, out_c, stride, norm_layer)\n",
    "        elif in_c > out_c:\n",
    "            self.residual = upsampling2DV1(in_c, out_c, stride, norm_layer)\n",
    "        elif stride > 1:\n",
    "            self.residual = downsampling2DV2(in_c, out_c, stride, norm_layer)\n",
    "        else:\n",
    "            self.residual = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = x\n",
    "        x = self.b1(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.c1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.a2(x)\n",
    "        x = self.c2(x)\n",
    "        s = self.residual(s)\n",
    "        x = x + s\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d232acd4-9dbc-429b-aa57-d47d1d8b587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVariationalEncoderV1(nn.Module):\n",
    "    def __init__(self, ic, chmuls, hmul):\n",
    "        super(ConvVariationalEncoderV1, self).__init__()\n",
    "        layer1 = []\n",
    "        outmul = 1\n",
    "        for mul in chmuls:\n",
    "            layer1.append(nn.Conv2d(ic*outmul, ic*mul, (3,3), (2,2), (1,1)))\n",
    "            layer1.append(nn.ReLU(inplace=True))\n",
    "            outmul = mul\n",
    "        self.layer1 = nn.ModuleList(layer1)\n",
    "        self.mu_layer = nn.Conv2d(ic*outmul, ic*hmul, (3,3), (2,2), (1,1))\n",
    "        self.sig_layer = nn.Sequential(\n",
    "            nn.Conv2d(ic*outmul, ic*hmul, (3,3), (2,2), (1,1)),\n",
    "            nn.Softplus(threshold=6),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layer1:\n",
    "            x = layer(x)\n",
    "        mu = self.mu_layer(x)\n",
    "        sig = self.sig_layer(x)\n",
    "        return (mu, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b2d131-c923-4d41-88ba-f4a876d14372",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVariationalEncoderV2(nn.Module):\n",
    "    def __init__(self, ic, chmuls, hmul):\n",
    "        super(ConvVariationalEncoderV2, self).__init__()\n",
    "        layer1 = []\n",
    "        outmul = 1\n",
    "        for mul in chmuls:\n",
    "            layer1.append(ResidualLayer2DV4(ic*outmul, ic*mul, 3, relu_activation, nn.BatchNorm2d, stride=2))\n",
    "            outmul = mul\n",
    "        self.layer1 = nn.ModuleList(layer1)\n",
    "        self.mu_layer = nn.Conv2d(ic*outmul, ic*hmul, (3,3), (2,2), (1,1))\n",
    "        self.sig_layer = nn.Sequential(\n",
    "            nn.Conv2d(ic*outmul, ic*hmul, (3,3), (2,2), (1,1)),\n",
    "            nn.Softplus(threshold=6),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layer1:\n",
    "            x = layer(x)\n",
    "        mu = self.mu_layer(x)\n",
    "        sig = self.sig_layer(x)\n",
    "        return (mu, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1dc912d-3661-4cf6-91b7-8b1709bd0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDecoderV1(nn.Module):\n",
    "    def __init__(self, ic, chmuls, hmul):\n",
    "        super(ConvDecoderV1, self).__init__()\n",
    "        layers = []\n",
    "        outmul = hmul\n",
    "        for mul in reversed(chmuls):\n",
    "            layers.append(nn.ConvTranspose2d(ic*outmul, ic*mul, (4,4), (2,2), (1,1)))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            outmul = mul\n",
    "        layers.append(nn.ConvTranspose2d(ic*outmul, ic, (4,4), (2,2), (1,1)))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ee918f7-0a7a-4735-9c09-f7b2f214d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDecoderV2(nn.Module):\n",
    "    def __init__(self, ic, chmuls, hmul):\n",
    "        super(ConvDecoderV2, self).__init__()\n",
    "        layers = []\n",
    "        outmul = hmul\n",
    "        for mul in reversed(chmuls):\n",
    "            layers.append(ResidualLayer2DV4(ic*outmul, ic*mul, 3, relu_activation, nn.BatchNorm2d, stride=2))\n",
    "            outmul = mul\n",
    "        layers.append(ResidualLayer2DV4(ic*outmul, ic, 3, relu_activation, nn.BatchNorm2d, stride=2))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "076b8bd0-8eeb-400c-983f-535f61b112b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVariationalAutoEncoderV1(nn.Module):\n",
    "    def __init__(self, ic, chmuls, hmul, dist):\n",
    "        super(ConvVariationalAutoEncoderV1, self).__init__()\n",
    "        self.encoder = ConvVariationalEncoderV1(ic, chmuls, hmul)\n",
    "        self.decoder = ConvDecoderV1(ic, chmuls, hmul)\n",
    "        self.dist = dist\n",
    "    \n",
    "    def forward(self, x, device):\n",
    "        mu, sig = self.encoder(x)\n",
    "        s = self.dist.sample(sig.shape).to(device)\n",
    "        z = mu + sig * s\n",
    "        x_h = self.decoder(z)\n",
    "        return (x_h, mu, sig)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mu, sig = self.encoder(x)\n",
    "        return (mu, sig)\n",
    "\n",
    "    def decode(self, mu, sig, device):\n",
    "        s = self.dist.sample(mu.shape).to(device)\n",
    "        z = mu + sig * s\n",
    "        x_h = self.decoder(z)\n",
    "        return x_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f02cd58-e90b-4057-8df0-96f08f86dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVariationalAutoEncoderV2(nn.Module):\n",
    "    def __init__(self, ic, chmuls, hmul, dist):\n",
    "        super(ConvVariationalAutoEncoderV2, self).__init__()\n",
    "        self.encoder = ConvVariationalEncoderV2(ic, chmuls, hmul)\n",
    "        self.decoder = ConvDecoderV2(ic, chmuls, hmul)\n",
    "        self.dist = dist\n",
    "    \n",
    "    def forward(self, x, device):\n",
    "        mu, sig = self.encoder(x)\n",
    "        s = self.dist.sample(sig.shape).to(device)\n",
    "        z = mu + sig * s\n",
    "        x_h = self.decoder(z)\n",
    "        return (x_h, mu, sig)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mu, sig = self.encoder(x)\n",
    "        return (mu, sig)\n",
    "\n",
    "    def decode(self, mu, sig, device):\n",
    "        s = self.dist.sample(mu.shape).to(device)\n",
    "        z = mu + sig * s\n",
    "        x_h = self.decoder(z)\n",
    "        return x_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7adfa227-5f15-4e87-8f00-1742cba2d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_image_train(model, device, loader, optimizer, loss, epoch, reporter):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for x, _ in loader:\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        x_h, mu, sig = model(x, device)\n",
    "        l = loss(x_h, x, mu, sig)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += l.item()\n",
    "    total_loss /= float(len(loader.dataset))\n",
    "    reporter.report(typ='train', loss=total_loss)\n",
    "    print(f\"Train Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c1d041c-d19a-4a27-b1a2-1378985f551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_image_validate(model, device, loader, loss, train_epoch, reporter):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for x, _ in loader:\n",
    "            x = x.to(device)\n",
    "            x_h, mu, sig = model(x, device)\n",
    "            total_loss += loss(x_h, x, mu, sig)\n",
    "    total_loss /= float(len(loader.dataset))\n",
    "    reporter.report(typ='eval', loss=total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d965b597-bcd6-4cff-833d-d269763209a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_image_train_validate(\n",
    "        model,\n",
    "        device,\n",
    "        train_loader,\n",
    "        eval_loader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        loss,\n",
    "        total_epoch,\n",
    "        patience,\n",
    "        patience_decay,\n",
    "        reporter,\n",
    "):\n",
    "    validation_loss = float(\"inf\")\n",
    "    patience_count = patience\n",
    "    patience = int(patience * patience_decay)\n",
    "    reset_patience = False\n",
    "    for epoch in range(total_epoch):\n",
    "        vae_image_train(model, device, train_loader, optimizer, loss, epoch, reporter)\n",
    "        vae_image_validate(model, device, eval_loader, loss, epoch, reporter)\n",
    "        new_validation_loss = reporter.eval_loss(-1)\n",
    "        print(f\"Epoch {epoch} VLoss: {new_validation_loss}\")\n",
    "        scheduler.step(new_validation_loss)\n",
    "        if new_validation_loss < validation_loss:\n",
    "            validation_loss = new_validation_loss\n",
    "            patience_count = patience\n",
    "            if reset_patience:\n",
    "                patience = int(patience * patience_decay)\n",
    "                reset_patience = False\n",
    "        else:\n",
    "            validation_loss = new_validation_loss\n",
    "            patience_count -= 1\n",
    "            reset_patience = True\n",
    "            if patience_count <= 0:\n",
    "                print(f\"Improvement stopped. VLoss: {validation_loss}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6db3aed8-1ef8-407e-8b1d-874f65f7ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "### datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8c0dc5-8ef8-4ada-a6a9-c18b6629c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(root=data_dir, train=True, transform=transforms.ToTensor(), download=True)\n",
    "evalset  = datasets.MNIST(root=data_dir, train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "320dd6f6-169a-4fee-ad4b-e745e40243fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0265ee2c41ee4d9ba0a2e4bd5b58f7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root=data_dir, train=True, transform=transforms.ToTensor(), download=True)\n",
    "evalset = datasets.CIFAR10(root=data_dir, train=True, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c6ee0-80b4-4882-a895-12895d364a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.CIFAR100(root=data_dir, train=True, transform=transforms.ToTensor(), download=True)\n",
    "evalset = datasets.CIFAR100(root=data_dir, train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bf2df5a-3b4e-4c0f-b17a-f2b9aa7d5339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 50000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(evalset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bfb2a0e-c99d-4639-b86f-cdbdd1d1769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = utils.data.DataLoader(dataset=trainset, **loader_args)\n",
    "eval_loader = utils.data.DataLoader(dataset=evalset, **score_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "053eec42-8cc9-4935-b764-4e68c715e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfb0fb0f-3ddf-402a-9890-8fe8fba5f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dist = distributions.Normal(0, 1)\n",
    "in_channel = trainset[0][0].shape[0]\n",
    "model = ConvVariationalAutoEncoderV2(in_channel, [in_channel*2], in_channel*4, norm_dist)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40bef63f-4606-4363-bd5b-7ba492c9d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "total_epochs = 60\n",
    "patience = 8\n",
    "patience_decay = 0.9\n",
    "optimizer = optim.Adam(model.parameters(recurse=True), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=patience/4, threshold=0.01)\n",
    "loss = VAELoss()\n",
    "reporter = SReporter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39369bc-4907-43dd-8172-d15bdb9f7b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3939.8987575\n",
      "Epoch 0 VLoss: 2688.265869140625\n",
      "Train Loss: 2102.2113778125\n",
      "Epoch 1 VLoss: 1743.615966796875\n",
      "Train Loss: 1507.27000078125\n",
      "Epoch 2 VLoss: 1343.02587890625\n",
      "Train Loss: 1238.6249925\n",
      "Epoch 3 VLoss: 1157.8890380859375\n",
      "Train Loss: 1103.719003125\n",
      "Epoch 4 VLoss: 1063.71533203125\n",
      "Train Loss: 1034.91108\n",
      "Epoch 5 VLoss: 1013.8659057617188\n",
      "Train Loss: 999.460096875\n",
      "Epoch 6 VLoss: 988.7303466796875\n",
      "Train Loss: 979.3172359375\n",
      "Epoch 7 VLoss: 972.2191162109375\n",
      "Train Loss: 966.49983859375\n",
      "Epoch 8 VLoss: 960.8378295898438\n",
      "Train Loss: 957.39248375\n",
      "Epoch 9 VLoss: 953.56982421875\n",
      "Train Loss: 950.5582271875\n",
      "Epoch 10 VLoss: 947.914794921875\n",
      "Train Loss: 945.2179196875\n",
      "Epoch 11 VLoss: 943.3482055664062\n",
      "Train Loss: 940.7150909375\n",
      "Epoch 12 VLoss: 938.4014282226562\n",
      "Train Loss: 937.19405875\n",
      "Epoch 13 VLoss: 936.0698852539062\n",
      "Train Loss: 934.218559375\n",
      "Epoch 14 VLoss: 932.833984375\n",
      "Train Loss: 931.66979859375\n",
      "Epoch 15 VLoss: 930.550048828125\n",
      "Train Loss: 930.4141521875\n",
      "Epoch 16 VLoss: 929.8525390625\n",
      "Train Loss: 930.1234965625\n",
      "Epoch 17 VLoss: 929.6898193359375\n",
      "Train Loss: 929.833770625\n",
      "Epoch 18 VLoss: 929.5665283203125\n",
      "Train Loss: 929.69723515625\n",
      "Epoch 19 VLoss: 929.4012451171875\n",
      "Train Loss: 929.65573875\n",
      "Epoch 20 VLoss: 929.6586303710938\n",
      "Train Loss: 929.6736575\n",
      "Epoch 21 VLoss: 929.3362426757812\n",
      "Train Loss: 929.74015578125\n"
     ]
    }
   ],
   "source": [
    "vae_image_train_validate(model, device, train_loader, eval_loader, optimizer, scheduler, loss, total_epochs, patience, patience_decay, reporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0490d98-6bab-4c60-8c46-ec41c73fca45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
